人工智能的极限

现在，我们能把有关人工智能极限的哲学论点的各种特性归纳到一起了。人工智能领域分成两个子领域：认知模拟（CS）与人工智能（AI），从而要处理两个相互独立而又相互关联的问题：（1）人在“信息加工”中是否真的象数字计算机那样遵循形式化规则？（2）人类行为，无论如何生成的，能否描述为一种可由数字机实现的形式化系统？

在逐个讨论这些问题时，我们首先发现，离开传统的哲学偏见加以考虑，从描写性和现象学的证据中看出，所有形式的智能行为中都包含着不可程序化的人类能力。另外，我们还看到，没有任何与此相反的证据经得起方法论上的推敲。因此，只要人工智能是否可能的问题还是一种经验性的问题，其答案是：在认识模拟或人工智能中再取得有意义的进展是极其不可能的。

如果人工智能研究者们面对这些困难，依旧希望证实他们的乐观主义观点，那么这种证明的重担便落在他们自己身上了。他们必须证明尽管有经验性的困难，人工智能肯定是可能的。但是在这方面，支持人工智能的先验性理由要比经验性的更脆弱。正是那种理应证明形式化一定是可能的论断，结果不是支离破碎就是自相矛盾，相反却说明，除了某些已被一致意见所排除、极其不可能的经验性假想外，形式化是不可能的。这样一来，肯定形式化的先验性论点变成原则上有条件否定CS与AI可能性的论点。

让我们详细地回顾一下这些论点。在讨论CS时，我们发现人类在进行象棋对奕游戏时，在解答复杂问题时，在识别相似性和家族近似性时，在修辞性地使用语言时，在我们感到奇怪或不符合语法的方面，在他们自己或观察者们看来，似乎并不遵循严格的规则。相反，倒好象使用全局性的感知组织，并在本质与非本质运算之间，做实用性的区分，求助于范式实例和使用一种关于局势的共同感觉，以达到相互交流。

当然，所有这些有序显然又是非规则性的活动，可能仍是无意识遵循规则的结构。但是，当人们想把这些看成一种所有行为都必须理解为产生于一组指令的哲学见解时，便碰到使用规则的规则的回归现象。这种回归无法靠求助于普通事实的方法终结，因为按照原有的主张，这些事实本身必须用规则来识别和解释。

有一种避免这一回归的方法是认为终极数据是物理能的输入，而这些输入总可以按照规则被加工和数字化。弗多就持有这种观点。关于这些输入是象数字程序那样在一个运算序列中被加工的主张，不是不可理解的，但是象弗多所承认的，要求有一个尚未有人能发现或发明出来难以想象的复杂形式化系统。由于没有经验性或先验性的论断证明，这种用于加工物理输入的形式化系统真的存在或应该存在，又有了大脑象模拟计算机那样工作的经验性论据，那么没有理由认为，反倒有各种理由怀疑大脑中物理输入的加工，取数字计算机程序的形式。

避免规则回归的唯一方法，是修改认为在最低层次上规则无须指令而自动使用的论点和主张。但这在两个方面会引起麻烦：（1）一旦那种认为所有行为必定
